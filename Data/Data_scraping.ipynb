{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUjMosnuDbZy"
      },
      "source": [
        "# <a>Data scraping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "703D6nSV-M6D"
      },
      "source": [
        "> ![](https://miro.medium.com/max/720/0*8KckBNQgI3o2CU3c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKkBa6ApAZ0V"
      },
      "source": [
        "> Photo by [Benjamin BalÃ¡zs](https://unsplash.com/@brenkee?utm_source=medium&utm_medium=referral) on [Unsplash](https://unsplash.com/@brenkee?utm_source=medium&utm_medium=referral)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zVEmCAyfKRV"
      },
      "source": [
        "> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e8ps24tNfW0h4G3dTIDFN5oBk7Dkba4n?usp=sharing) This NoteBook for data Labeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN2EYs6b-TIw"
      },
      "source": [
        "> ### Install Emoji Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AEehAZclsHG",
        "outputId": "574e5452-ca43-42b5-fe88-518cce90a6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.9.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2022.9.24)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install snscrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF3Gp_YbxF1c"
      },
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjoJU6KR-h2z"
      },
      "source": [
        "> ### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USF-kN1SlvtP",
        "outputId": "64c10e28-d27b-44e7-9cfe-60e87da9262f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Schreibt mir mal bitte random Themen/Challenge...\n",
            "1     (\\_/)\\n( â€¢_â€¢)\\n/ &gt;â¤\\n\\nWeil ich euch Kackbr...\n",
            "2     Welchen streamer schaut ihr am liebsten? Ich s...\n",
            "3     Ich kann gar nicht sagen wie Abgrund tief vera...\n",
            "4                    TAMPONS for free fÃ¼r alle â¤â¤â¤â¤â¤â¤â¤â¤\n",
            "...                                                 ...\n",
            "4995  MHIEEEEEEEEEEEEEEEE â¤â¤â¤â¤â¤â¤â¤â¤â¤\\n\\n#GirlsGenerat...\n",
            "4996  Gerade im Regio; Durchsage dass das 9-Euro-Tic...\n",
            "4997            Timaya, Adekunle Gold and Kizz Daniel â¤\n",
            "4998  Ich finde es immer wieder super cool, was Leud...\n",
            "4999  45 Minuten VerspÃ¤tung wegen TÃ¼rstÃ¶rung und wir...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "query = \"â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ’• -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('â¤.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VZspH-1mRfS",
        "outputId": "2575bb02-938a-4ec7-b487-23be482c6b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Kudos an die Macher von #ThePlaylist fÃ¼r den R...\n",
            "1                              Hydrangea Hills, Japan ğŸ˜\n",
            "2     Eine Freundin hat mir heute vom John Harris Fi...\n",
            "3     Josi Henning als Co-KommentatorinğŸ˜ \\n der Aben...\n",
            "4             Bin jetzt fÃ¼r 1 Jahr wieder inaktiv byeee\n",
            "...                                                 ...\n",
            "4995  Nichts macht mich glÃ¼cklicher als eine Redbull...\n",
            "4996  Grad aus dem fancy Haus der Industrie raus und...\n",
            "4997  Falls ihr morgen eine mÃ¼de End-DreiÃŸigerin auf...\n",
            "4998  Ob's wohl nÃ¤chste Woche Mal in die groÃŸe Stadt...\n",
            "4999  Will nichts sagen, aber rÃ¼ckblickend hÃ¤tte man...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜ -â¤ -ğŸ˜‚ -ğŸ’• -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-nkrfY62TjC",
        "outputId": "7783b379-25cf-4105-974c-be7e9e5d014d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Ich werde wirklich alt.\\nIch habe mein Handy a...\n",
            "1     Liz Truss tritt zurÃ¼ck.ğŸ˜‚\\nGestern Thema im Spa...\n",
            "2     Ich stelle mir jetzt jemanden vor, der nach Je...\n",
            "3     Klussi soooo genial, wie verbissen er kÃ¤mpft! ...\n",
            "4     Lauf grad auf offener StraÃŸe rum, telefoniere ...\n",
            "...                                                 ...\n",
            "4995  Endlich hat Trymbi seinen Nasus auf der Suppor...\n",
            "4996                             Prayers for Mikaben ğŸ™ğŸ¿\n",
            "4997  Wie ich heute ziemlich regelmÃ¤ÃŸig zwischen Pro...\n",
            "4998  Warum Liefers besser wie ein Kind mit einem Ba...\n",
            "4999  .@Nutellaprinz und ich haben gerade ein super ...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜‚ -â¤ -ğŸ˜ -ğŸ’• -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜‚.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h1jZlAA2TsG",
        "outputId": "cffcd06f-712c-4a8d-e3d0-50e19fccc608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0                            Ganen o ğŸš˜ğŸ”¥ @BocaJrsOficial\n",
            "1     BalloontownNFT ATSNFT LFG AmoenNFT NfRichardd ...\n",
            "2     Quick post~ \\nWir starten um 19Uhr Live mit #V...\n",
            "3     Kay One Song vermutlich in der ersten November...\n",
            "4        ich komme auf dieses twitter update nicht klar\n",
            "...                                                 ...\n",
            "4995                               Daniel Kofi KyerehğŸ”¥ğŸ”¥\n",
            "4996  Daniel Kofi-Kyereh on the score sheet for SC F...\n",
            "4997                              Daniel-Kofi KyerehğŸ”¥ğŸ”¥ğŸ”¥\n",
            "4998         Daniel-Kofi Kyereh âš½, my star player ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n",
            "4999  Wie wir mit diesem TrÃ¼mmerhaufen von Roster hi...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ”¥ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ’• -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ”¥.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn-c702v2T3H",
        "outputId": "158b0104-db5d-4e2b-fd22-8392cec88a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     frauen die tÃ¼rksich sprechen= ğŸ¦ğŸµğŸ¦§\\n\\nfrauen di...\n",
            "1             Alles Gute zum Geburtstag @20Jens10  ğŸ°ğŸ¹ğŸ‰ğŸ˜Š\n",
            "2     Heute gab es lecker Lasagne.\\nJetzt noch ein k...\n",
            "3     Gerade die erste Sitzung meiner Ãœbung zur Einf...\n",
            "4     Das war ja mal Spannung bis zum Schluss ğŸ˜³\\nAbe...\n",
            "...                                                 ...\n",
            "4995  Ich feier die Omma grad Ã¼ber mir, sie hat Camo...\n",
            "4996                         Guten Morgen ihr Lieben. ğŸ˜Š\n",
            "4997  Guten Morgen erstmal kaffee trinken â˜•ï¸ â˜•ï¸ ğŸ™‹â€â™‚ï¸...\n",
            "4998  Guten Morgen â˜•ğŸ˜Š Ich wÃ¼nsche euch einen entspan...\n",
            "4999  Ich freue mich, dass meine TL-WG dem Herrn @ju...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜Š -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ’• -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜Š.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydvyf1r32T9e",
        "outputId": "ee6cfb3c-a7fb-4efd-9419-93142721f929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Okay .. ich machâ€™s ğŸ˜\\nWo muss ich unterschreib...\n",
            "1     Hab mir die ersten vier Folgen Cyberpunk Edger...\n",
            "2     SchÃ¶n an so nem Urlaub ist ja auch, dass man s...\n",
            "3                      15 mins till Modern Warfare II ğŸ˜\n",
            "4                  Pflaume geh weg ... \\n#gefragtgejagt\n",
            "...                                                 ...\n",
            "4995  Samstage, ey. Seit 8:45 Uhr alle Fenster geput...\n",
            "4996  Ich spiele nun dunkle seelen auf 4k tv weil st...\n",
            "4997  Jetzt mÃ¼ssen die Jungen noch fÃ¼r die Ukraine f...\n",
            "4998  Wochenende, endlich Zeit fÃ¼r ... Vorbereitunge...\n",
            "4999  HÃ¶re seit Tagen sehr viel #BRLRS und freue mic...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ’• -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yvfZqse2UCM",
        "outputId": "0475bcab-e70e-4610-8f6c-72c3013e3cfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0              Feminismus oder SchlÃ¤gerei #NurDreiWorte\n",
            "1     Manakugel voll ğŸ”µ\\nInventar gut bestÃ¼ckt ğŸ“œ\\nDas...\n",
            "2                 hamburger cheesburger big mac whopper\n",
            "3     Ratet mal wer grade einkaufen war und auf dem ...\n",
            "4     Politik is auch nur noch hoffen dass der Schad...\n",
            "...                                                 ...\n",
            "4995  Imagine, du willst zwei Freunden bei einem Dis...\n",
            "4996  cw abuse\\n\\nManchmal wurde ich in einer Umarmu...\n",
            "4997                                    Alles ist gut âœ¨\n",
            "4998  Sage main den sonra Harbor main gelir mi :D #V...\n",
            "4999  Jedes mal wenn ich durch den Leipzig hbf gehe ...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"âœ¨ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -ğŸ’• -ğŸ’™ -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('âœ¨.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw4lXGur2UGT",
        "outputId": "beb0d55a-add6-4e81-8444-06a8fa7b92f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:snscrape.base:Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_composer_source=true&include_ext_alt_text=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=%F0%9F%92%99+-%E2%9D%A4+-%F0%9F%98%8D+-%F0%9F%98%82+-%F0%9F%94%A5+-%F0%9F%98%8A+-%F0%9F%98%8E+-%E2%9C%A8+-%F0%9F%92%95+-%F0%9F%98%98+-%F0%9F%93%B7+-%F0%9F%87%BA%F0%9F%87%B8+-%E2%98%80+-%F0%9F%92%9C+-%F0%9F%98%89+-%F0%9F%92%AF+-%F0%9F%98%81+-%F0%9F%8E%84+-%F0%9F%93%B8+-%F0%9F%98%9C++lang%3Ade+-filter%3Alinks+-filter%3Areplies&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwNHlyZ_c9CsWgICj3ajzuPgrEnEVgMR3FYCJehgHREVGQVVMVDUBFc4BFQAA&pc=1&spelling_corrections=1&ext=mediaStats%252CcameraMoment: ConnectionError(ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))), retrying\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     ğŸ¾EUROPEAN OPEN ANTWERP\\nğŸ‡§ğŸ‡ªGoffin vs ğŸ‡¦ğŸ‡·Schwartzman\n",
            "1                                    GOL DEL WOLFSBURGO\n",
            "2     Patrioten, Lesemodus steht an, sonst bekomme i...\n",
            "3     Donnerstagnachmittagcortisonspritzensofalethargie\n",
            "4     Gibt es wirklich Familien, die so Familienfeie...\n",
            "...                                                 ...\n",
            "4995                                        Freiburg ğŸ’™ğŸ’™\n",
            "4996  Liebe an Disney+, dass sie immer noch \"PlÃ¶tzli...\n",
            "4997                #UsedomKrimi das war wohl nichts. ğŸ™„\n",
            "4998                                Nhi aoge idhar.ğŸ˜”ğŸ˜”ğŸ˜”ğŸ˜”\n",
            "4999  Ganz schÃ¶ne Schlappe fÃ¼r das #Iqwig, die Exper...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ’™ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’• -ğŸ˜˜ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ’™.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WCP6R3o2UJk",
        "outputId": "3aeea1e2-02b1-4c71-b73b-d4c957318ead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Oma weiÃŸ einfach was ich zum Feierabend brauch...\n",
            "1     DankeschÃ¶n  an euch alle, die fest die Daumen ...\n",
            "2     Vom Nudeln essen geht es geschmeidig weiter au...\n",
            "3     MittagsschlÃ¤fchen jetzt? Na klar, is erst sech...\n",
            "4     â€mir taugt zwar finance aber wollt die sbwl ni...\n",
            "...                                                 ...\n",
            "4995  FÃ¼r alle, die es noch nicht wussten, mein Herz...\n",
            "4996  Die liebe @Serenityhebtab hat heute Geburtstag...\n",
            "4997  EntzÃ¼ckt nehme ich zur Kenntnis, dass itunes h...\n",
            "4998  #Tuchel und #Tedesco sind eben nicht Ole Werne...\n",
            "4999  Da ich es gerade wieder gesehen habe... was so...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜˜ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜˜.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUlpOpFM3Obm",
        "outputId": "42999853-9226-422b-94ab-ac0cb807beb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     BERLIN taz | Der Zuschlag kommt: RentÂ­neÂ­r:inÂ­...\n",
            "1     #attilahildmann derğŸ¤¡ glaubt das er nur wegen P...\n",
            "2     Sebastian Kurz: wir in Ã–sterreich ğŸ‡¦ğŸ‡¹ sind scho...\n",
            "3     Seh ich wie Tom: mein idealer Mann ist ein Man...\n",
            "4           Es gibt nur 2 #Geschlechter fertig aus ende\n",
            "...                                                 ...\n",
            "4995  ğŸ‡ºğŸ‡¸ San JosÃ© Sharks v Seattle Kraken \\nğŸ’ San Jo...\n",
            "4996  ğŸ‰ Latest Winners\\n\\nğŸ‡®ğŸ‡¹ Torino - Cagliari\\nâœ… Ca...\n",
            "4997  HÃ¤tten alle Staaten wie #Deutschland der #Ukra...\n",
            "4998  VUELTA 52 DE 100 !!!\\nMCLAUGHLIN YA EN TERCER ...\n",
            "4999  Ich habe heute schon fÃ¼nf Love scammer geblock...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ‡ºğŸ‡¸ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ‡ºğŸ‡¸.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8o99E6Z3gFL",
        "outputId": "c88060f2-8d19-4016-bd8b-ec4327f1b0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     19:00 #Wetter â˜€ Klare 12,5Â°C, Taupunkt: 8,6Â°C,...\n",
            "1            RÃ¼cktritt statt Fortschritt\\n#NurDreiWorte\n",
            "2                           Aus die Maus\\n#NurDreiWorte\n",
            "3     18:00 #Wetter â˜€ Klare 13,2Â°C, Taupunkt: 8,8Â°C,...\n",
            "4     Nietzschean Hellenism, aristocracy, wisdom, vi...\n",
            "...                                                 ...\n",
            "1330  15:00 #Wetter â˜€ Klare 15,3Â°C, Taupunkt: -0,6Â°C...\n",
            "1331  14:00 #Wetter â˜€ Klare 14,5Â°C, Taupunkt: -0,9Â°C...\n",
            "1332  13:00 #Wetter â˜€ Klare 13,4Â°C, Taupunkt: -0,7Â°C...\n",
            "1333  12:00 #Wetter â˜€ Klare 11,6Â°C, Taupunkt: -1,3Â°C...\n",
            "1334  11:00 #Wetter â˜€ Klare 8,8Â°C, Taupunkt: -2,3Â°C,...\n",
            "\n",
            "[1335 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"â˜€ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('â˜€.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq1hh-_C2UN8",
        "outputId": "96b8f594-8580-4ddc-9078-3341ed495c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0                     Genug ist genug.\\n\\n#NurDreiWorte\n",
            "1     Mein neues Hobby ist Eugen verarschen indem ic...\n",
            "2              die Briten haben Vertruss mit Truss.....\n",
            "3     Dauert die Lame Duck-Periode bei VdB jetzt bis...\n",
            "4     Wieder zurÃ¼ck, total Ko, bin knapp 17km gelauf...\n",
            "...                                                 ...\n",
            "2507  Ich liebÃ¤ugle sehr damit, mir eine gute #Kamer...\n",
            "2508  Projektkoordination? Social media? Transmedial...\n",
            "2509  Manche hier geben bei Fotos, die nicht von ihn...\n",
            "2510  Folgt doch bitte der @ApfelundZimt ğŸğŸğŸ\\n\\nWund...\n",
            "2511                                   ğŸ“·: bayleeraeanne\n",
            "\n",
            "[2512 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ“· -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ“·.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgpOxRTN4ds6",
        "outputId": "f5572ea1-782c-49d2-b0f6-defa510e787c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Meine Mutter schlÃ¤gt seit Tagen mit einem feuc...\n",
            "1     Gut dann mach ich jetzt mal WÃ¶lfe-TV aus und s...\n",
            "2     Das war amateurhaft den Fuss reingehalten. #WO...\n",
            "3     Okay Liz Truss tritt zurÃ¼ck und Boris Johnson ...\n",
            "4     Also wenn ich China wÃ¤re wÃ¼rde ich den Hamburg...\n",
            "...                                                 ...\n",
            "4995  Blitzer zwischen #Herbolzheim und #Untergriesh...\n",
            "4996                                  Lass re ğŸ“¸ anochee\n",
            "4997  morgen fÃ¤hrt der ğŸ© fÃ¼r zwei tage nach Mannheim...\n",
            "4998            Next is PokÃ©mon snap but with Prompto ğŸ“¸\n",
            "4999                             Ellen Von Unwerth | ğŸ“¸ğŸ’š\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ“¸ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ“¸.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atmzjrh53o2D",
        "outputId": "7b8e9706-6773-4bda-a179-ee598a4ca1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0             40 MINUTEN DANN NEUER PETER FOX SONG AAAA\n",
            "1                         was geht was geht meine babys\n",
            "2                        Couch aubergine  #HouseOfGames\n",
            "3     mach fÃ¼r heute mal ne kleine stream pause uwu\\...\n",
            "4     ğŸ’‰ğŸ’‰ğŸ’‰ğŸ’‰ âœ…\\n\\nHier, Berlin:\\nDas Impfzentrum im Ri...\n",
            "...                                                 ...\n",
            "4995  Ich kann abends im Pulli und Wollsocken sitzen...\n",
            "4996  Ich weiÃŸ nicht wie, ich weiÃŸ nicht warum, aber...\n",
            "4997  1/ Channel by STC\\n\\n2/ STC Solution\\n\\n3/ STC...\n",
            "4998  1/ Channel by STC\\n\\n2/ STC Solution\\n\\n3/ STC...\n",
            "4999  ZurÃ¼ck von der #Gamescom und ich muss sagen: E...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ’œ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ’œ.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I_LUsbG302r",
        "outputId": "61aa2d05-915d-4eb9-ebed-6f488dddd073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Hey @SWEG_SBS die Taktzeiten beim SEV zwischen...\n",
            "1     Winterreifen ins Auto geladen, weil ich vor la...\n",
            "2     Hab auch Hemnes im Esszimmer stehen ğŸ˜‰  #JKGalileo\n",
            "3     Heute letztes Modul zu den Barrierescouts der ...\n",
            "4     Freundschaftliches Date ğŸ˜‰ğŸ˜‰ğŸ˜‰\\nKnick, Knack. \\n#...\n",
            "...                                                 ...\n",
            "4995  Heute war #Jahrgangselternabend der neuen 5er ...\n",
            "4996                 ğŸ›‹ï¸ha...ich hab die Couch gefundenğŸ˜‰\n",
            "4997  Hier hat sich ja die 1. Garde der Sherlocks un...\n",
            "4998  Mein Haupt Account 2 wurde wieder dauerhaft ge...\n",
            "4999  DAS sagt die Richtige!!! ğŸ˜‰ \\nHast schon DAVID ...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜‰ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜‰.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A63iL_Jr3_jY",
        "outputId": "8943c300-b79a-4ab9-8df1-b2d263a41911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0                             Eric Ten Hag has balls ğŸ’€ğŸ’¯\n",
            "1                Hi meine lieben na alles jut bei euch?\n",
            "2            Wer schÃ¶n sein will, muss freundlich sein.\n",
            "3                leberkas semmel: ein âœ…ğŸ’¯\\nwelt: aus ğŸš«â€¼ï¸\n",
            "4                                   RichhumansNFT LFG ğŸ’¯\n",
            "...                                                 ...\n",
            "4995            Sei keine Pu$$y und Makiere dein CrushğŸ’¯\n",
            "4996  Ich glaube ich bin montag der weg ich gehasst ...\n",
            "4997         Noch 2 Tage dann haben wir es geschafft ğŸ’¯ğŸ¤\n",
            "4998                         Ion understand mfs nomo ğŸ’¯.\n",
            "4999  hab mir 4 monate mÃ¼he gegeben fÃ¼r etwas, wo ic...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ’¯ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ˜ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ’¯.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8rB9N6U4JRA",
        "outputId": "b7ea730b-5082-4edf-b053-e65e884331fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Apple Watch 4 44mm &amp; Cellular fÃ¼r 40â‚¬ geka...\n",
            "1     Ich habe einen 13 Jahre alten Dune Prime 3 als...\n",
            "2     in den Trends von \"Silent Hill\" zulesen macht ...\n",
            "3     Dieser Blick schon wieder...ja Klaas, du hast ...\n",
            "4          So, morgen steht wieder Hunde sitting an. ğŸ˜ğŸ¶\n",
            "...                                                 ...\n",
            "4995  Immer so ein kleiner Grinsepups wenn die Ã„rzte...\n",
            "4996  Streamchen nachher? Nice. Machen heute Cyberpu...\n",
            "4997  Hey ihr Lieben,\\nAuf der Arbeit sind wir dabei...\n",
            "4998  Morgen gibt es hier wohl ein neues Kleidungsst...\n",
            "4999  Mein Mann wirklich keine Ahnung. Der wusste ni...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ„ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UYMz2iw4Trz",
        "outputId": "80c20677-88d5-46f8-b355-24ba8c42044c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0                             wer zum teufel ist amanda\n",
            "1     Hahaha, das hat ja lange gedauert, jetzt folgt...\n",
            "2     Bist du ein Dieb? Weil du mein Herz gestohlen ...\n",
            "3       Feuer !!! Feuer in meinem Herzen! #TEN_Birthday\n",
            "4     Hey, du siehst aus wie mein nÃ¤chster Freund. #...\n",
            "...                                                 ...\n",
            "4995  ğŸ„Ich wÃ¼nsche allen ein frohes und besinnliches...\n",
            "4996  WÃ¼nsche euch einen schÃ¶nen Tag und alles Gute ...\n",
            "4997            Schoko NikolÃ¤use im Haus verteilt ğŸ¥°ğŸ„ğŸ¤¶ğŸğŸ’«\n",
            "4998                               Frohe Weihnachten ğŸğŸ„\n",
            "4999  Liebe Follower, ich wÃ¼nsche euch allen frohe W...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ„ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ“¸ -ğŸ˜œ  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ„.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWpVPlCR4nFi",
        "outputId": "7fc11f79-b43b-4d13-8a29-1d81f41509ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Doha - Alkohol wird voraussichtlich erlaubt (s...\n",
            "1                Glaubst du an Schicksal? #TEN_Birthday\n",
            "2     WeiÃŸt du, welche Seite meines Herzens? Es ist ...\n",
            "3     In die Welt kÃ¶nnen Sie eine Person sein, aber ...\n",
            "4     Hey, du siehst aus wie mein nÃ¤chster Freund. #...\n",
            "...                                                 ...\n",
            "4995  Ich sprÃ¤che FranzÃ¶sisch mit einem leichten bel...\n",
            "4996                    Max Scherzer â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸â¤ï¸ğŸ˜œğŸ˜œ\n",
            "4997  Ganz gewisse, spezielle Sauna-Abende, haben ei...\n",
            "4998  Der Anzug ğŸ˜œ aufgehende Sonne â˜€ï¸#goodbyedeutsch...\n",
            "4999  sie: und wie hast du geschlafen?\\n\\nich: wie e...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ˜œ -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ’• -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ˜œ.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO27BhtWaSD4",
        "outputId": "a2072400-2914-48e0-82b6-b9ef863f2b59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                  Tweet\n",
            "0     Weiter Sachen auf EKA verschenkt und ganz unve...\n",
            "1     Ich bin nicht toxic, ich hab nur deinem Arbeit...\n",
            "2     Was wÃ¼rden wir nur ohne den Bruder machen! Der...\n",
            "3     meine kerl*innen\\n\\nich wÃ¼rde gerne\\nğŸ’• ab und ...\n",
            "4                                          Grind mode ğŸ˜Œ\n",
            "...                                                 ...\n",
            "4995                                    Gnn gemtee ğŸ«‚ğŸ’•ğŸ’—ğŸ’—\n",
            "4996                                 Lrt Chopper ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ’•\n",
            "4997                                 LRTS ERASERMIC ğŸ¥ºğŸ’•ğŸ’•\n",
            "4998            ğŸ’­ğŸ¥Ÿâ¨11.08.22â¨2:35AM KST\\n\\nDuerme bien!ğŸ’•\n",
            "4999  So, jetzt muss ich aber wirklich gehen \\n..\\nG...\n",
            "\n",
            "[5000 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "query = \"ğŸ’• -â¤ -ğŸ˜ -ğŸ˜‚ -ğŸ”¥ -ğŸ˜Š -ğŸ˜ -âœ¨ -ğŸ’™ -ğŸ˜˜ -ğŸ˜œ -ğŸ“· -ğŸ‡ºğŸ‡¸ -â˜€ -ğŸ’œ -ğŸ˜‰ -ğŸ’¯ -ğŸ˜ -ğŸ„ -ğŸ“¸  lang:de -filter:links -filter:replies\"\n",
        "tweets = []\n",
        "limit = 5000\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit:\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Tweet'])\n",
        "print(df)\n",
        "\n",
        "# to save to csv\n",
        "df.to_csv('ğŸ’•.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zgj4rrtYX6Gh"
      },
      "outputs": [],
      "source": [
        "e=['â¤','ğŸ˜','ğŸ˜‚','ğŸ’•','ğŸ”¥','ğŸ˜Š','ğŸ˜','âœ¨','ğŸ’™','ğŸ˜˜','ğŸ“·','ğŸ‡ºğŸ‡¸','â˜€','ğŸ’œ','ğŸ˜‰','ğŸ’¯','ğŸ˜','ğŸ„','ğŸ“¸','ğŸ˜œ']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ38jMGlYaD_",
        "outputId": "fa5672e4-6096-4ba6-c967-c46dca836492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnP1zQuX4wJ1"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "for i in e:\n",
        "  shutil.copy(\"/content/\"+i+\".csv\",\"/content/drive/MyDrive/Hamoly_German\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nc0RN_vaIvS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4e7960e88b0decf9e9fb148be570b38b9d4677c430d15e8d68c4159fa566a13e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
