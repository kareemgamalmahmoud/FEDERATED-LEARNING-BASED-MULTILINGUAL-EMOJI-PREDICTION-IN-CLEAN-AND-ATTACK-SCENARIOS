{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "qL_BkAe9GdYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install flower"
      ],
      "metadata": {
        "id": "744f7q1UBE8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the data from Google Drive"
      ],
      "metadata": {
        "id": "nXuXCSIMBMDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "url = \"https://drive.google.com/drive/folders/13ijZBGIVAm-x93YpWKqIRe9alJa-O45K?usp=sharing\"\n",
        "gdown.download_folder(url)"
      ],
      "metadata": {
        "id": "PGOHoXwDBLex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "s2VoBls-G9gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import re"
      ],
      "metadata": {
        "id": "u31uJyC7HtlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "onBxP98nHvlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import Metrics\n",
        "from torch.utils.data import DataLoader, random_split"
      ],
      "metadata": {
        "id": "hlNdiAryHx8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from emoji import demojize\n",
        "from transformers import AutoModel, AutoTokenizer,BertForSequenceClassification, AdamW, BertConfig,get_linear_schedule_with_warmup\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "zteI1nVoHihp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### This is a special cleaning for SemEval english data only"
      ],
      "metadata": {
        "id": "JOyw4mqHBtDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "def normalizeToken(token):\n",
        "    token = token.strip()\n",
        "    lowercased_token = token.lower().strip()\n",
        "    # print(token)\n",
        "    if token != \" \":\n",
        "        if token.startswith(\"@\"):\n",
        "            return \"@USER\"\n",
        "        elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n",
        "            return \"HTTPURL\"\n",
        "        # elif len(token) == 1:\n",
        "        #     return demojize(token)\n",
        "        else:\n",
        "            if token == \"’\":\n",
        "                return \"'\"\n",
        "            elif token == \"…\":\n",
        "                return \"...\"\n",
        "            else:\n",
        "                return token\n",
        "\n",
        "\n",
        "def normalizeTweet(tweet):\n",
        "    tok = TweetTokenizer()\n",
        "    tokens = tok.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n",
        "    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n",
        "    # print(normTweet)\n",
        "    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n",
        "    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \",\" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n",
        "    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\").replace(\" p . m \", \" p.m \").replace(\" a . m .\",\" a.m.\").replace(\" a . m \",\" a.m \")\n",
        "    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n",
        "    normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n",
        "    normTweet = normTweet.lower()\n",
        "    return \" \".join(normTweet.split())\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# this method just for splitting \n",
        "def splitting_method(df_, name1 ,name2, test_size = 0.5):\n",
        "  y = pd.DataFrame(df_, columns = [\"label\"])  \n",
        "  X = pd.DataFrame(df_, columns = ['sentence'])\n",
        "\n",
        "  X_train, X_test ,y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=True, random_state=105)\n",
        "\n",
        "  df_t = pd.DataFrame(X_train, columns = ['sentence'])\n",
        "  df_yt = pd.DataFrame(y_train, columns = ['label'])\n",
        "\n",
        "  train_data = pd.concat([df_t, df_yt], axis=1)\n",
        "  train_data.to_csv(name1+\".csv\", index = False,)\n",
        "\n",
        "  df_xtest = pd.DataFrame(X_test, columns = ['sentence'])\n",
        "  df_ytest = pd.DataFrame(y_test, columns = ['label'])\n",
        "\n",
        "  test_data = pd.concat([df_xtest, df_ytest], axis=1)\n",
        "  # print(test_data.isnull().sum())\n",
        "  if test_size != 0.5:\n",
        "        \n",
        "    test_data = test_data.drop_duplicates('sentence')\n",
        "    \n",
        "  test_data.to_csv(name2+\".csv\", index = False,)\n",
        "\n",
        "  # return train_data\n",
        "  return test_data"
      ],
      "metadata": {
        "id": "-ZQK_3twH9Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Usign the GPU or CPR"
      ],
      "metadata": {
        "id": "LJNOg-DvM712"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "jhL8TsC4ICqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Read the original SemEval dataset"
      ],
      "metadata": {
        "id": "NGExckFiM3VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.concat(map(pd.read_csv, [ '/home/jovyan/conda-envs/dj/DATA/Karim_140K_es.csv','/home/jovyan/conda-envs/dj/DATA/Karim_300K_it.csv','/home/jovyan/conda-envs/dj/DATA/Karim_450K_fr.csv']))\n",
        "temp.to_csv(\"training_es_it_fr.csv\", index = False,)\n",
        "df_3L_train = pd.read_csv('training_es_it_fr.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "\n",
        "df1 = pd.read_csv('/home/jovyan/conda-envs/dj/DATA/test/us_test.text', sep='\\n\\n', names=['sentence'])\n",
        "df2 = pd.read_csv('/home/jovyan/conda-envs/dj/DATA/test/us_test.labels', sep='\\n\\n', names=['label'])\n",
        "\n",
        "df = pd.concat([df1, df2], axis=1)\n",
        "df\n",
        "df.to_csv(\"devFile.csv\", index = False,)\n",
        "\n",
        "\n",
        "df1 = pd.read_csv('/home/jovyan/conda-envs/dj/DATA/us/tweet_by_ID_28_1_2019__06_28_21.txt.text', sep='\\n\\n', names=['sentence'])\n",
        "df2 = pd.read_csv('/home/jovyan/conda-envs/dj/DATA/us/tweet_by_ID_28_1_2019__06_28_21.txt.labels', sep='\\n\\n', names=['label'])\n",
        "\n",
        "\n",
        "df = pd.concat([df1, df2], axis=1)\n"
      ],
      "metadata": {
        "id": "Yb4wcr91IFog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can call it :)\n",
        "splitting_method(df,'centralized_dataset','fedrated_dataset',test_size = 0.5)"
      ],
      "metadata": {
        "id": "WVbAkvoDIKQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Model intialization"
      ],
      "metadata": {
        "id": "Z2Q2mwn6Mux2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT = \"Twitter/twhin-bert-base\"\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CHECKPOINT, \n",
        "    num_labels = 20,   \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")"
      ],
      "metadata": {
        "id": "6Lc2M3HzINjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Load the pretrained model."
      ],
      "metadata": {
        "id": "VydtDQnFMm6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('model path', map_location=torch.device(device))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)"
      ],
      "metadata": {
        "id": "AzCyHP7zIbt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Dataframe to dataloader function"
      ],
      "metadata": {
        "id": "JxFhYbz2MdM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_dataloader(data_frame):\n",
        "\n",
        "  # trainFile = '/content/centralized_dataset.csv'\n",
        "  # devFile = '/content/devFile.csv'\n",
        "  # df = pd.read_csv(trainFile)\n",
        "  # df_dev = pd.read_csv(devFile)\n",
        "\n",
        "  df = data_frame\n",
        "\n",
        "  print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "  # print('Number of dev sentences: {:,}\\n'.format(df_dev.shape[0]))\n",
        "  df['sentence']  = df.sentence.apply(normalizeTweet)\n",
        "  df.dropna()\n",
        "  # df_dev['sentence']  = df_dev.sentence.apply(normalizeTweet)\n",
        "  # df_dev.dropna()\n",
        "\n",
        "\n",
        "\n",
        "  # Get the lists of sentences and their labels.\n",
        "  sentences = df.sentence.values\n",
        "  labels = df.label.values\n",
        "  # sentences_dev = df_dev.sentence.values\n",
        "  # labels_dev = df_dev.label.values\n",
        "  tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "\n",
        "  input_ids = []\n",
        "  # input_ids_dev = []\n",
        "\n",
        "  for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(sent)\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "  # for sent_dev in sentences_dev:\n",
        "  #   encoded_sent_dev = tokenizer.encode(sent_dev)\n",
        "  #   input_ids_dev.append(encoded_sent_dev)\n",
        "\n",
        "\n",
        "  MAX_LEN = 64\n",
        "  #MAX_LEN = 128\n",
        "  print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "  print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "  # input_ids_dev = pad_sequences(input_ids_dev, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "  print('\\nDone.')\n",
        "  # Create attention masks\n",
        "\n",
        "\n",
        "  attention_masks = []\n",
        "  # attention_masks_dev = []\n",
        "  for sent in input_ids:\n",
        "      att_mask = [int(token_id > 0) for token_id in sent]\n",
        "      attention_masks.append(att_mask)\n",
        "\n",
        "  # for sent_dev in input_ids_dev:\n",
        "  #     att_mask_dev = [int(token_id > 0) for token_id in sent_dev]\n",
        "  #     attention_masks_dev.append(att_mask_dev)\n",
        "\n",
        "\n",
        "  train_inputs = input_ids\n",
        "  # validation_inputs = input_ids_dev\n",
        "\n",
        "  train_labels = labels\n",
        "  print(\"train_labels: \",set(train_labels))\n",
        "  \n",
        "  # validation_labels = labels_dev\n",
        "  # print(\"validation_labels: \",set(validation_labels))\n",
        "  \n",
        "  train_masks = attention_masks\n",
        "  # validation_masks = attention_masks_dev\n",
        "  \n",
        "  train_inputs = torch.tensor(train_inputs)\n",
        "  # validation_inputs = torch.tensor(validation_inputs)\n",
        "  \n",
        "  train_labels = torch.tensor(train_labels)\n",
        "  print(\"train_labels: \",train_labels)\n",
        "  \n",
        "  # validation_labels = torch.tensor(validation_labels)\n",
        "  # print(\"validation_labels: \",validation_labels)\n",
        "  \n",
        "  train_masks = torch.tensor(train_masks)\n",
        "  # validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "\n",
        "  batch_size = 64\n",
        "  # Create the DataLoader for our training set.\n",
        "  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "  # Create the DataLoader for our validation set.\n",
        "  # validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "  # validation_sampler = SequentialSampler(validation_data)\n",
        "  # validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader\n"
      ],
      "metadata": {
        "id": "qixOPZzLJq38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### testing data set"
      ],
      "metadata": {
        "id": "pAohNFuLMNrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataloader = Data_to_dataloader(\"/content/fedrated_dataset.csv\")\n",
        "fed_data = pd.read_csv('fedrated_dataset.csv')\n",
        "validation_dataloader = Data_to_dataloader('devFile.csv') \n",
        "\n",
        "\n",
        "test_German = pd.read_csv('/DATA/german_zero_shot_54K.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "test_German.to_csv(\"test_German.csv\", index = False,)\n",
        "\n",
        "test_old_en = pd.read_csv('/DATA/test_en_27k.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "test_old_en.to_csv(\"test_old_en.csv\", index = False,)\n",
        "\n",
        "test_es = pd.read_csv('/DATA/test_es_29k_final.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "test_es.to_csv(\"test_es.csv\", index = False,)\n",
        "\n",
        "test_fr = pd.read_csv('/DATA/test_fr_63k_final.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "test_fr.to_csv(\"test_fr.csv\", index = False,)\n",
        "\n",
        "test_it = pd.read_csv('/DATA/test_it_36k_final.csv', skiprows=1, names=['Tweet','Label_2','label','sentence'])\n",
        "test_it.to_csv(\"test_it.csv\", index = False,)\n"
      ],
      "metadata": {
        "id": "xJE84OOQJuyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> convert it to dataloader"
      ],
      "metadata": {
        "id": "92Z9HyOtMYh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "German_validation_dataloader = Data_to_dataloader('test_German.csv') \n",
        "es_validation_dataloader = Data_to_dataloader('test_es.csv') \n",
        "fr_validation_dataloader = Data_to_dataloader('test_fr.csv') \n",
        "it_validation_dataloader = Data_to_dataloader('test_it.csv') "
      ],
      "metadata": {
        "id": "IdNUHhMNJwNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Non-IID training dataset"
      ],
      "metadata": {
        "id": "CtRZgJlxMKXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_non_c_zero_toxic = pd.concat(map(pd.read_csv, [ '/DATA/new_toxic_2_4_non_iid/Client_0_EN_non_IID_Toxic_Data.csv']))\n",
        "df_train_non_c_zero_toxic.to_csv(\"training_non_iid_c_zero.csv\", index = False,)\n",
        "df_train_non_c_zero_toxic = pd.read_csv('training_non_iid_c_zero.csv', skiprows=1, names=['sentence','Label_2','label'])\n",
        "\n",
        "\n",
        "df_train_non_c_1 = pd.concat(map(pd.read_csv, [ '/DATA/new_toxic_2_4_non_iid/Client_1_FR_non_IID_Toxic_Data.csv']))\n",
        "df_train_non_c_1.to_csv(\"training_non_iid_c_1.csv\", index = False,)\n",
        "df_train_non_c_1 = pd.read_csv('training_non_iid_c_1.csv', skiprows=1, names=['sentence','Label_2','label'])\n",
        "\n",
        "\n",
        "\n",
        "df_train_non_c_2 = pd.concat(map(pd.read_csv, [ '/DATA/new_toxic_2_4_non_iid/NonIID_It_clients_151K.csv']))\n",
        "df_train_non_c_2.to_csv(\"training_non_iid_c_2.csv\", index = False,)\n",
        "df_train_non_c_2 = pd.read_csv('training_non_iid_c_2.csv', skiprows=1, names=['sentence','label','sen_2','Label_2'])\n",
        "\n",
        "\n",
        "\n",
        "df_train_non_c_3 = pd.concat(map(pd.read_csv, [ '/DATA/new_toxic_2_4_non_iid/NonIID_Es_clients_70K.csv']))\n",
        "df_train_non_c_3.to_csv(\"training_non_iid_c_3.csv\", index = False,)\n",
        "df_train_non_c_3 = pd.read_csv('training_non_iid_c_3.csv', skiprows=1, names=['sentence','label','sen_2','Label_2'])\n"
      ],
      "metadata": {
        "id": "OrqbqUmNJzpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Training"
      ],
      "metadata": {
        "id": "kBx1UWUKMGcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "\n",
        "def train_fun(epoch_i, train_dataloader, model):\n",
        "\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = 2e-5,\n",
        "                    eps = 1e-8\n",
        "                  )\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                              num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "  # This training code is based on the `run_glue.py` script here:\n",
        "  # https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "  seed_val = 42\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)\n",
        "  # Store the average loss after each epoch so we can plot them.\n",
        "  loss_values = []\n",
        "\n",
        "  # ========================================\n",
        "  #               Training\n",
        "  # ========================================\n",
        "  # Perform one full pass over the training set.\n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "  print('Training...')\n",
        "  # Measure how long the training epoch takes.\n",
        "  t0 = time.time()\n",
        "  # Reset the total loss for this epoch.\n",
        "  total_loss = 0\n",
        "  # Put the model into training mode. Don't be mislead--the call to \n",
        "  # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "  # `dropout` and `batchnorm` layers behave differently during training\n",
        "  # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "  model.train()\n",
        "\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "      if step % 40 == 0 and not step == 0:\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      # Always clear any previously calculated gradients before performing a\n",
        "      # backward pass. PyTorch doesn't do this automatically because \n",
        "      # accumulating the gradients is \"convenient while training RNNs\". \n",
        "      # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "      model.zero_grad()\n",
        "      # The documentation for this `model` function is here: \n",
        "      # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "      outputs = model(b_input_ids, \n",
        "                  token_type_ids=None, \n",
        "                  attention_mask=b_input_mask, \n",
        "                  labels=b_labels)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      total_loss += loss.item()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "    \n",
        "      gc.collect()\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "  loss_values.append(avg_train_loss)\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  # name_save = 'xT_bert_tweets_en_semEval_epoch_'+ str(epoch_i) + '.pt'  \n",
        "  # torch.save(model,name_save)\n"
      ],
      "metadata": {
        "id": "jrcyfwfmKHIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### Validation"
      ],
      "metadata": {
        "id": "O0YGqaYzMBsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_fun(validation_dataloader, model):\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    predictions , true_labels = [], []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        \n",
        "\n",
        "    print('    DONE.')\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    \n",
        "    flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "    flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "    flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "    # labelsList = ['0','1','2']\n",
        "    # classif_rep = classification_report(flat_true_labels, flat_predictions, target_names=labelsList)\n",
        "    classif_rep = classification_report(flat_true_labels, flat_predictions, digits=5)\n",
        "    print(classif_rep)\n",
        "\n",
        "    return eval_accuracy/nb_eval_steps , eval_accuracy"
      ],
      "metadata": {
        "id": "9aTJnbJDKKch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTuR4RsdLRco"
      },
      "source": [
        "### Implementing a Flower client\n",
        "\n",
        "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Return the current local model parameters\n",
        "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
        "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "We mentioned that our clients will use the previously defined PyTorch components for model training and evaluation. Let's see a simple Flower client implementation that brings everything together:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, validation_dataloader, es_validation_dataloader, fr_validation_dataloader, it_validation_dataloader, German_validation_dataloader, df_train_non_fr_trainloader, df_train_non_Es_trainloader, df_train_non_It_trainloader, cid):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.validation_dataloader = validation_dataloader\n",
        "        self.es_validation_dataloader = es_validation_dataloader\n",
        "        self.fr_validation_dataloader = fr_validation_dataloader\n",
        "        self.it_validation_dataloader = it_validation_dataloader\n",
        "        self.German_validation_dataloader = German_validation_dataloader\n",
        "\n",
        "\n",
        "        self.cid = cid\n",
        "        \n",
        "        self.df_train_non_fr_trainloader = df_train_non_fr_trainloader\n",
        "        self.df_train_non_Es_trainloader = df_train_non_Es_trainloader\n",
        "        self.df_train_non_It_trainloader = df_train_non_It_trainloader\n",
        "        \n",
        "\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        # train(self.net, self.trainloader, epochs=1)\n",
        "        \n",
        "        \n",
        "        if self.cid == '0':\n",
        "            train_fun(1, self.trainloader, self.net)\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if self.cid == '1':\n",
        "            train_fun(1, self.df_train_non_fr_trainloader, self.net)\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if self.cid == '2':\n",
        "            train_fun(1, self.df_train_non_Es_trainloader, self.net)\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            \n",
        "        if self.cid == '3':\n",
        "            train_fun(1, self.df_train_non_It_trainloader, self.net)\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            \n",
        "            \n",
        "        return self.get_parameters(config={}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        # loss, accuracy = test(self.net, self.valloader)\n",
        "\n",
        "        print('SemEval_test_>>>')\n",
        "        loss, accuracy = test_fun(self.validation_dataloader, self.net)\n",
        "\n",
        "        print('ES_test_>>>')\n",
        "        loss, accuracy = test_fun(self.es_validation_dataloader, self.net)\n",
        "        \n",
        "        print('FR_test_>>>')\n",
        "        loss, accuracy = test_fun(self.fr_validation_dataloader, self.net)\n",
        "        \n",
        "        print('IT_test_>>>')\n",
        "        loss, accuracy = test_fun(self.it_validation_dataloader, self.net)\n",
        "        \n",
        "        print('GR_test_>>>')\n",
        "        loss, accuracy = test_fun(self.German_validation_dataloader, self.net)\n",
        "\n",
        "        # name_save = '/home/jovyan/conda-envs/dj/models_/n1_ex2_iid_MMini__multilingual_epoch_.pt'  \n",
        "        # torch.save(self.net, name_save)\n",
        "        \n",
        "        mypath = '/home/jovyan/conda-envs/dj/models_'\n",
        "        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "        new_name = 'n1_ex2_toxic_2table_2_4_noniid_Mmini_Krum_2g_epoch_R5.pt'\n",
        "        while(new_name in onlyfiles):\n",
        "          new_name = new_name[:-3] + \"_R_\" + new_name[-3:]\n",
        "        torch.save(self.net, mypath + '/' + new_name)\n",
        "\n",
        "\n",
        "        return float(loss), len(self.validation_dataloader), {\"accuracy\": float(accuracy)}\n",
        "    \n",
        "    \n"
      ],
      "metadata": {
        "id": "YiduNvI7KSE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_1CDC0kLRcr"
      },
      "source": [
        "### Using the Virtual Client Engine\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 4 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 4 clients would mean having 4 instances of `FlowerClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 4\n",
        "\n",
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    partition_size = len(fed_data) // NUM_CLIENTS\n",
        "    idx_from, idx_to = int(cid) * partition_size, (int(cid) + 1) * partition_size\n",
        "\n",
        "\n",
        "    # train_dataloader\n",
        "    # trainloader = df_to_dataloader(fed_data.iloc[idx_from:idx_to])\n",
        "    trainloader = df_to_dataloader(df_train_non_c_zero_toxic)\n",
        "    \n",
        "    df_train_non_fr_trainloader = df_to_dataloader(df_train_non_c_1)\n",
        "    df_train_non_Es_trainloader = df_to_dataloader(df_train_non_c_2)\n",
        "    df_train_non_It_trainloader = df_to_dataloader(df_train_non_c_3)\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(model, trainloader, validation_dataloader, es_validation_dataloader, fr_validation_dataloader, it_validation_dataloader, German_validation_dataloader, df_train_non_fr_trainloader, df_train_non_Es_trainloader, df_train_non_It_trainloader, cid)\n"
      ],
      "metadata": {
        "id": "B0x2j8d3KT-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import WARNING\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import (\n",
        "    FitRes,\n",
        "    MetricsAggregationFn,\n",
        "    NDArrays,\n",
        "    Parameters,\n",
        "    Scalar,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "\n",
        "from aggregate import aggregate_krum\n",
        "from flwr.server.strategy.fedavg import FedAvg\n",
        "\n",
        "# FedAvg = fl.server.strategy.FedAvg()\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
        "Setting `min_available_clients` lower than `min_fit_clients` or\n",
        "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
        "connected to the server. `min_available_clients` must be set to a value larger\n",
        "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "zGojCHi1KXIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emTierlFHJix"
      },
      "outputs": [],
      "source": [
        "# flake8: noqa: E501\n",
        "class Krum(FedAvg):\n",
        "    \"\"\"Configurable Krum strategy implementation.\"\"\"\n",
        "\n",
        "    # pylint: disable=too-many-arguments,too-many-instance-attributes,line-too-long\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        num_malicious_clients: int = 0,\n",
        "        num_clients_to_keep: int = 0,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Configurable Krum strategy.\n",
        "        Parameters\n",
        "        ----------\n",
        "        fraction_fit : float, optional\n",
        "            Fraction of clients used during training. Defaults to 0.1.\n",
        "        fraction_evaluate : float, optional\n",
        "            Fraction of clients used during validation. Defaults to 0.1.\n",
        "        min_fit_clients : int, optional\n",
        "            Minimum number of clients used during training. Defaults to 2.\n",
        "        min_evaluate_clients : int, optional\n",
        "            Minimum number of clients used during validation. Defaults to 2.\n",
        "        min_available_clients : int, optional\n",
        "            Minimum number of total clients in the system. Defaults to 2.\n",
        "        num_malicious_clients : int, optional\n",
        "            Number of malicious clients in the system. Defaults to 0.\n",
        "        num_clients_to_keep : int, optional\n",
        "            Number of clients to keep before averaging (MultiKrum). Defaults to 0, in that case classical Krum is applied.\n",
        "        evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
        "            Optional function used for validation. Defaults to None.\n",
        "        on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure training. Defaults to None.\n",
        "        on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure validation. Defaults to None.\n",
        "        accept_failures : bool, optional\n",
        "            Whether or not accept rounds containing failures. Defaults to True.\n",
        "        initial_parameters : Parameters, optional\n",
        "            Initial global model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_evaluate=fraction_evaluate,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
        "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
        "        self.num_malicious_clients = num_malicious_clients\n",
        "        self.num_clients_to_keep = num_clients_to_keep\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        rep = f\"Krum(accept_failures={self.accept_failures})\"\n",
        "        return rep\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using Krum.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # Convert results\n",
        "        weights_results = [\n",
        "            (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "        parameters_aggregated = ndarrays_to_parameters(\n",
        "            aggregate_krum(\n",
        "                weights_results, self.num_malicious_clients, self.num_clients_to_keep\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQINEwDaLRcw"
      },
      "source": [
        "The only thing left to do is to tell the strategy to call this function whenever it receives evaluation metric dictionaries from the clients:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# strategy = fl.server.strategy.FedAvg(\n",
        "# Krum(\n",
        "# Create FedAvg strategy\n",
        "strategy = Krum(\n",
        "        # fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        # fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
        "        # min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "        # min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        # min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "# client_resources = None\n",
        "# if DEVICE.type == \"cuda\":\n",
        "\n",
        "client_resources = {\"num_gpus\": 1/5,  \"num_cpus\": 32/4}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=1),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")\n"
      ],
      "metadata": {
        "id": "36JCG189KcLr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}